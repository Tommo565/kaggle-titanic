{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on the whole dataset\n",
    "# Categorical variable for age\n",
    "# Combining classifiers\n",
    "# Voting Classifier\n",
    "# Has an infant variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 1_feature_engineering.py\n",
    "%run 2_test_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = './data/titanic_train.csv'\n",
    "test_data = './data/titanic_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data(train_data,test_data)\n",
    "df = feature_engineering(df)\n",
    "df_train = df[( df['train'] == 1 )]\n",
    "df_test = df[( df['test'] == 1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweet_features = [\n",
    "    'pclass', 'is_alone', 'sex_0', 'sex_1', 'title_1', 'title_2', 'title_3', \n",
    "    'title_4', 'title_5', 'title_6', 'family_size_1', 'family_size_2', 'family_size_3', \n",
    "    'group_size_1', 'group_size_2', 'group_size_3', 'age_scaled'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance: 83.05%\n",
      "SVC Performance: 83.39%\n",
      "Linear SVC Performance: 82.72%\n",
      "Naive Bayes Performance: 81.7%\n",
      "KNN Performance: 82.39%\n",
      "Decision Tree Performance: 81.82%\n",
      "Random Forest Performance: 82.61%\n",
      "Gradient Boosting Performance: 83.73%\n",
      "MLP Performance: 83.62%\n"
     ]
    }
   ],
   "source": [
    "features = df_train[sweet_features]\n",
    "label = df_train['survived']\n",
    "test_models(models, sweet_features, features, label, 5, './logs/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Score:  0.8338945005611672\n",
      "Params:  {'C': 1, 'gamma': 0.1}\n",
      "Estimator:  SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['rbf', 'sigmoid']\n",
    "    'C': [1,10,100,1000],\n",
    "    'gamma': ['auto', 1, 0.1, 0.001, 0.0001],\n",
    "    'shrinking': [True, False]\n",
    "}\n",
    "model = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=5\n",
    ")\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 16 candidates, totalling 800 fits\n",
      "Score:  0.8282828282828283\n",
      "Params:  {'C': 1, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "Estimator:  LinearSVC(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 800 out of 800 | elapsed:   18.5s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    'penalty': ['l1'],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'dual': [False],\n",
    "    'C':[1,10,100,1000],\n",
    "    'class_weight': ['balanced', None]      \n",
    "}, {\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge'],\n",
    "    'dual': [True],\n",
    "    'C':[1,10,100,1000],\n",
    "    'class_weight': ['balanced', None]    \n",
    "}]\n",
    "model = GridSearchCV(\n",
    "    LinearSVC(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=50\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 32 candidates, totalling 1600 fits\n",
      "Score:  0.8305274971941639\n",
      "Params:  {'C': 1, 'multi_class': 'ovr', 'solver': 'newton-cg'}\n",
      "Estimator:  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1600 out of 1600 | elapsed:   59.7s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C':[1,10,100,1000],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'multi_class': ['ovr', 'multinomial']        \n",
    "}\n",
    "model = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=50\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8372615039281706\n",
      "Params:  {'alpha': 0.1, 'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'adam'}\n",
      "Estimator:  MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=4, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver': ['lbfgs','adam'], \n",
    "    'max_iter': [500,1000,1500], \n",
    "    'alpha': 10.0 ** -np.arange(1, 7), \n",
    "    'hidden_layer_sizes': np.arange(3, 8)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=3\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
