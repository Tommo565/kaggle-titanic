{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA on the whole dataset\n",
    "# Categorical variable for age\n",
    "# Combining classifiers\n",
    "# Voting Classifier\n",
    "# Has an infant variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 1_feature_engineering.py\n",
    "%run 2_test_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = './data/titanic_train.csv'\n",
    "test_data = './data/titanic_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = import_data(train_data,test_data)\n",
    "df = feature_engineering(df)\n",
    "df_train = df[( df['train'] == 1 )]\n",
    "df_test = df[( df['test'] == 1 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweet_features = [\n",
    "    'pclass', 'is_alone', 'sex_0', 'sex_1', 'title_1', 'title_2', 'title_3', \n",
    "    'title_4', 'title_5', 'title_6', 'family_size_1', 'family_size_2', 'family_size_3', \n",
    "    'group_size_1', 'group_size_2', 'group_size_3', 'age_scaled'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Mean: 83.08%\n",
      "Logistic Regression STD: 7.895\n",
      "Logistic Regression Min: 66.67%\n",
      "Logistic Regression Max: 100.0%\n",
      "SVC Mean: 83.53%\n",
      "SVC STD: 8.045\n",
      "SVC Min: 66.67%\n",
      "SVC Max: 100.0%\n",
      "Linear SVC Mean: 82.86%\n",
      "Linear SVC STD: 7.565\n",
      "Linear SVC Min: 66.67%\n",
      "Linear SVC Max: 100.0%\n",
      "Naive Bayes Mean: 82.75%\n",
      "Naive Bayes STD: 7.845\n",
      "Naive Bayes Min: 66.67%\n",
      "Naive Bayes Max: 100.0%\n",
      "KNN Mean: 82.87%\n",
      "KNN STD: 8.835\n",
      "KNN Min: 61.11%\n",
      "KNN Max: 100.0%\n",
      "Decision Tree Mean: 82.07%\n",
      "Decision Tree STD: 8.525\n",
      "Decision Tree Min: 61.11%\n",
      "Decision Tree Max: 100.0%\n",
      "Random Forest Mean: 82.07%\n",
      "Random Forest STD: 9.015\n",
      "Random Forest Min: 61.11%\n",
      "Random Forest Max: 100.0%\n",
      "Gradient Boosting Mean: 83.65%\n",
      "Gradient Boosting STD: 8.525\n",
      "Gradient Boosting Min: 66.67%\n",
      "Gradient Boosting Max: 100.0%\n",
      "MLP Mean: 83.53%\n",
      "MLP STD: 7.965\n",
      "MLP Min: 66.67%\n",
      "MLP Max: 100.0%\n"
     ]
    }
   ],
   "source": [
    "features = df_train[sweet_features]\n",
    "label = df_train['survived']\n",
    "test_models(models, sweet_features, features, label, 50, './logs/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 160 candidates, totalling 8000 fits\n",
      "Score:  0.8383838383838383\n",
      "Params:  {'C': 1, 'decision_function_shape': 'ovr', 'gamma': 1, 'kernel': 'rbf', 'shrinking': True}\n",
      "Estimator:  SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 8000 out of 8000 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'kernel': ['rbf', 'sigmoid'],\n",
    "    'C': [1,10,100,1000],\n",
    "    'gamma': ['auto', 1, 0.1, 0.001, 0.0001],\n",
    "    'shrinking': [True, False],\n",
    "    'decision_function_shape': ['ovr', 'ovo']\n",
    "}\n",
    "model = GridSearchCV(\n",
    "    SVC(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=50\n",
    ")\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 16 candidates, totalling 800 fits\n",
      "Score:  0.8282828282828283\n",
      "Params:  {'C': 1, 'class_weight': None, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l1'}\n",
      "Estimator:  LinearSVC(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 800 out of 800 | elapsed:   18.5s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{\n",
    "    'penalty': ['l1'],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'dual': [False],\n",
    "    'C':[1,10,100,1000],\n",
    "    'class_weight': ['balanced', None]      \n",
    "}, {\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge'],\n",
    "    'dual': [True],\n",
    "    'C':[1,10,100,1000],\n",
    "    'class_weight': ['balanced', None]    \n",
    "}]\n",
    "model = GridSearchCV(\n",
    "    LinearSVC(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=50\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 32 candidates, totalling 1600 fits\n",
      "Score:  0.8305274971941639\n",
      "Params:  {'C': 1, 'multi_class': 'ovr', 'solver': 'newton-cg'}\n",
      "Estimator:  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1600 out of 1600 | elapsed:   59.7s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C':[1,10,100,1000],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'multi_class': ['ovr', 'multinomial']        \n",
    "}\n",
    "model = GridSearchCV(\n",
    "    LogisticRegression(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=50\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8372615039281706\n",
      "Params:  {'alpha': 0.1, 'hidden_layer_sizes': 4, 'max_iter': 500, 'solver': 'adam'}\n",
      "Estimator:  MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=4, learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'solver': ['lbfgs','adam'], \n",
    "    'max_iter': [500,1000,1500], \n",
    "    'alpha': 10.0 ** -np.arange(1, 7), \n",
    "    'hidden_layer_sizes': np.arange(3, 8)\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    MLPClassifier(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=3\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n",
      "Score:  0.8518518518518519\n",
      "Params:  {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 1.0, 'min_samples_leaf': 20}\n",
      "Estimator:  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
      "              max_features=1.0, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=20, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1440 out of 1440 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_leaf': [20, 50,100,150],\n",
    "    'max_features': [1.0, 0.3, 0.1] \n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    GradientBoostingClassifier(),\n",
    "    param_grid,\n",
    "    verbose=1, \n",
    "    cv=10\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "print('Score: ', model.best_score_)\n",
    "print('Params: ', model.best_params_)\n",
    "print('Estimator: ', model.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Model\n",
    "\n",
    "model = LogisticRegression(\n",
    "    C=1, \n",
    "    multi_class='ovr',\n",
    "    solver='newton-cg'\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['PassengerId'] = df_test['passengerid']\n",
    "df_sub['Survived'] = model.predict(df_test[sweet_features])\n",
    "sub_path = './data/submission_logistic.csv'\n",
    "df_sub.to_csv(sub_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Model\n",
    "\n",
    "model = SVC(\n",
    "    C=1, \n",
    "    decision_function_shape='ovr',\n",
    "    gamma=1,\n",
    "    kernel='rbf',\n",
    "    shrinking=True\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['PassengerId'] = df_test['passengerid']\n",
    "df_sub['Survived'] = model.predict(df_test[sweet_features])\n",
    "sub_path = './data/submission_SVC.csv'\n",
    "df_sub.to_csv(sub_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM Model\n",
    "\n",
    "model = LinearSVC(\n",
    "    C=1,\n",
    "    dual=False,\n",
    "    loss='squared_hinge',\n",
    "    penalty='l1'\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['PassengerId'] = df_test['passengerid']\n",
    "df_sub['Survived'] = model.predict(df_test[sweet_features])\n",
    "sub_path = './data/submission_linearSVC.csv'\n",
    "df_sub.to_csv(sub_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    min_samples_leaf=20,\n",
    "    max_features=1.0,\n",
    ")\n",
    "\n",
    "model.fit(features, label)\n",
    "\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['PassengerId'] = df_test['passengerid']\n",
    "df_sub['Survived'] = model.predict(df_test[sweet_features])\n",
    "sub_path = './data/submission_GBC.csv'\n",
    "df_sub.to_csv(sub_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
